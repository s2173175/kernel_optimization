[2022-07-09 23:27:41] COMMAND: train_auto.py -name walking_cmd_2_l_a -input_dims 13
[2022-07-09 23:27:41] Arguments: {'learning_rate': 0.001, 'dropout_prob': 0.2, 'l2': 0, 'max_epoch': 20, 'data_dir': ['./data/sets/walking_cmd_2_l_a_x.csv', './data/sets/walking_cmd_2_l_a_y.csv'], 'batch_size': 100, 'save_dir': './kernel/results/walking_cmd_2_l_a', 'log_file': './kernel/results/walking_cmd_2_l_a/training_logs.out', 'model_file': './kernel/results/walking_cmd_2_l_a/checkpoint_best.pt', 'device': device(type='cuda', index=0), 'mode': 'rollout-training', 'seed': None, 'decay_rate': 0.8}
[2022-07-09 23:27:41] Commencing training!
[2022-07-09 23:30:06] Epoch 000: loss 0.01051 | lr 5.341e-08 | validation_loss 1.393e-07
[2022-07-09 23:31:59] Epoch 000: loss 0.004712 | lr 5.341e-08 | validation_loss 1.293e-07
[2022-07-09 23:33:52] Epoch 000: loss 0.004463 | lr 5.341e-08 | validation_loss 1.209e-07
[2022-07-09 23:35:44] Epoch 000: loss 0.004322 | lr 5.341e-08 | validation_loss 1.062e-07
[2022-07-09 23:37:37] Epoch 000: loss 0.004221 | lr 5.341e-08 | validation_loss 9.584e-08
[2022-07-09 23:39:31] Epoch 000: loss 0.004143 | lr 5.341e-08 | validation_loss 1.011e-07
[2022-07-09 23:41:24] Epoch 000: loss 0.004093 | lr 5.341e-08 | validation_loss 1.025e-07
[2022-07-09 23:43:17] Epoch 000: loss 0.004044 | lr 5.341e-08 | validation_loss 9.187e-08
[2022-07-09 23:45:10] Epoch 000: loss 0.004002 | lr 5.341e-08 | validation_loss 9.422e-08
[2022-07-09 23:47:03] Epoch 000: loss 0.00398 | lr 5.341e-08 | validation_loss 8.381e-08
[2022-07-09 23:48:56] Epoch 000: loss 0.003956 | lr 5.341e-08 | validation_loss 8.532e-08
[2022-07-09 23:50:48] Epoch 000: loss 0.003928 | lr 5.341e-08 | validation_loss 8.354e-08
[2022-07-09 23:52:41] Epoch 000: loss 0.003918 | lr 5.341e-08 | validation_loss 7.907e-08
[2022-07-09 23:54:34] Epoch 000: loss 0.003901 | lr 5.341e-08 | validation_loss 8.598e-08
[2022-07-09 23:56:26] Epoch 000: loss 0.003896 | lr 5.341e-08 | validation_loss 7.921e-08
[2022-07-09 23:58:19] Epoch 000: loss 0.00389 | lr 5.341e-08 | validation_loss 7.847e-08
[2022-07-10 00:00:12] Epoch 000: loss 0.003884 | lr 5.341e-08 | validation_loss 7.613e-08
[2022-07-10 00:02:06] Epoch 000: loss 0.003875 | lr 5.341e-08 | validation_loss 7.852e-08
[2022-07-10 00:03:59] Epoch 000: loss 0.003873 | lr 5.341e-08 | validation_loss 8.559e-08
[2022-07-10 00:05:52] Epoch 000: loss 0.003866 | lr 5.341e-08 | validation_loss 7.673e-08
[2022-07-10 00:07:45] Epoch 000: loss 0.003877 | lr 5.341e-08 | validation_loss 7.856e-08
[2022-07-10 00:09:38] Epoch 000: loss 0.003864 | lr 5.341e-08 | validation_loss 7.554e-08
[2022-07-10 00:11:31] Epoch 000: loss 0.003861 | lr 5.341e-08 | validation_loss 7.704e-08
[2022-07-10 00:13:24] Epoch 000: loss 0.003867 | lr 5.341e-08 | validation_loss 7.738e-08
[2022-07-10 00:15:17] Epoch 000: loss 0.00386 | lr 5.341e-08 | validation_loss 8.039e-08
[2022-07-10 00:17:10] Epoch 000: loss 0.003861 | lr 5.341e-08 | validation_loss 7.58e-08
[2022-07-10 00:19:03] Epoch 000: loss 0.003858 | lr 5.341e-08 | validation_loss 7.532e-08
[2022-07-10 00:20:56] Epoch 000: loss 0.003862 | lr 5.341e-08 | validation_loss 7.888e-08
[2022-07-10 00:22:48] Epoch 000: loss 0.003853 | lr 5.341e-08 | validation_loss 8.388e-08
[2022-07-10 00:24:42] Epoch 000: loss 0.003855 | lr 5.341e-08 | validation_loss 7.566e-08
[2022-07-10 00:26:34] Epoch 000: loss 0.003854 | lr 5.341e-08 | validation_loss 7.656e-08
[2022-07-10 00:28:28] Epoch 000: loss 0.003854 | lr 5.341e-08 | validation_loss 7.803e-08
[2022-07-10 00:30:22] Epoch 000: loss 0.00386 | lr 5.341e-08 | validation_loss 8.35e-08
[2022-07-10 00:32:16] Epoch 000: loss 0.00385 | lr 5.341e-08 | validation_loss 7.734e-08
[2022-07-10 00:34:10] Epoch 000: loss 0.003851 | lr 5.341e-08 | validation_loss 8.017e-08
[2022-07-10 00:36:03] Epoch 000: loss 0.003848 | lr 5.341e-08 | validation_loss 7.642e-08
