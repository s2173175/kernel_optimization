[2022-07-11 09:42:51] COMMAND: train_auto.py -name walking_cmd_25 -input_dims 7
[2022-07-11 09:42:51] Arguments: {'learning_rate': 0.001, 'dropout_prob': 0.2, 'l2': 0, 'max_epoch': 20, 'data_dir': ['./data/sets/walking_cmd_25_x.csv', './data/sets/walking_cmd_25_y.csv'], 'batch_size': 100, 'save_dir': './kernel/results/walking_cmd_25', 'log_file': './kernel/results/walking_cmd_25/training_logs.out', 'model_file': './kernel/results/walking_cmd_25/checkpoint_best.pt', 'device': device(type='cuda', index=0), 'mode': 'rollout-training', 'seed': None, 'decay_rate': 0.8}
[2022-07-11 09:42:51] Commencing training!
[2022-07-11 09:45:23] Epoch 000: loss 0.01267 | lr 5.412e-08 | validation_loss 2.176e-07
[2022-07-11 09:47:22] Epoch 000: loss 0.006525 | lr 5.412e-08 | validation_loss 1.849e-07
[2022-07-11 09:49:20] Epoch 000: loss 0.006211 | lr 5.412e-08 | validation_loss 1.882e-07
[2022-07-11 09:51:17] Epoch 000: loss 0.006025 | lr 5.412e-08 | validation_loss 1.4e-07
[2022-07-11 09:53:15] Epoch 000: loss 0.005898 | lr 5.412e-08 | validation_loss 1.708e-07
[2022-07-11 09:55:12] Epoch 000: loss 0.005801 | lr 5.412e-08 | validation_loss 1.409e-07
[2022-07-11 09:57:02] Epoch 000: loss 0.005709 | lr 5.412e-08 | validation_loss 1.392e-07
[2022-07-11 09:58:50] Epoch 000: loss 0.005657 | lr 5.412e-08 | validation_loss 1.697e-07
[2022-07-11 10:00:49] Epoch 000: loss 0.005604 | lr 5.412e-08 | validation_loss 1.337e-07
[2022-07-11 10:02:46] Epoch 000: loss 0.005546 | lr 5.412e-08 | validation_loss 1.163e-07
[2022-07-11 10:04:42] Epoch 000: loss 0.005514 | lr 5.412e-08 | validation_loss 1.21e-07
[2022-07-11 10:06:33] Epoch 000: loss 0.005489 | lr 5.412e-08 | validation_loss 1.213e-07
[2022-07-11 10:08:21] Epoch 000: loss 0.00547 | lr 5.412e-08 | validation_loss 1.191e-07
[2022-07-11 10:10:08] Epoch 000: loss 0.005455 | lr 5.412e-08 | validation_loss 1.235e-07
[2022-07-11 10:11:56] Epoch 000: loss 0.005441 | lr 5.412e-08 | validation_loss 1.138e-07
[2022-07-11 10:13:45] Epoch 000: loss 0.00543 | lr 5.412e-08 | validation_loss 1.156e-07
[2022-07-11 10:15:37] Epoch 000: loss 0.005418 | lr 5.412e-08 | validation_loss 1.294e-07
[2022-07-11 10:17:25] Epoch 000: loss 0.005403 | lr 5.412e-08 | validation_loss 1.134e-07
[2022-07-11 10:19:14] Epoch 000: loss 0.005405 | lr 5.412e-08 | validation_loss 1.125e-07
[2022-07-11 10:21:02] Epoch 000: loss 0.005402 | lr 5.412e-08 | validation_loss 1.118e-07
[2022-07-11 10:22:50] Epoch 000: loss 0.005407 | lr 5.412e-08 | validation_loss 1.267e-07
[2022-07-11 10:24:39] Epoch 000: loss 0.005397 | lr 5.412e-08 | validation_loss 1.136e-07
[2022-07-11 10:26:27] Epoch 000: loss 0.005399 | lr 5.412e-08 | validation_loss 1.235e-07
[2022-07-11 10:28:16] Epoch 000: loss 0.005391 | lr 5.412e-08 | validation_loss 1.187e-07
[2022-07-11 10:30:03] Epoch 000: loss 0.005395 | lr 5.412e-08 | validation_loss 1.17e-07
[2022-07-11 10:31:52] Epoch 000: loss 0.005382 | lr 5.412e-08 | validation_loss 1.204e-07
[2022-07-11 10:33:40] Epoch 000: loss 0.005387 | lr 5.412e-08 | validation_loss 1.264e-07
[2022-07-11 10:35:36] Epoch 000: loss 0.005387 | lr 5.412e-08 | validation_loss 1.162e-07
[2022-07-11 10:37:33] Epoch 000: loss 0.00539 | lr 5.412e-08 | validation_loss 1.149e-07
